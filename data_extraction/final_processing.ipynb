{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d16e11",
   "metadata": {},
   "source": [
    "\\<w\\> : english word  \n",
    "\\<t\\> : type of the word (noun, verb...)  \n",
    "\\<b\\> : meaning - definition  \n",
    "\\<s\\> : subtype of the word (masculine, plural...)  \n",
    "\\<i\\> : correspondant amazigh word  \n",
    "\\<x\\> : an example illustrating the use of this amazigh word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b1ad6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "\n",
    "class AmWord(object):\n",
    "    def __init__(self, am_word, examples: list[str]):\n",
    "        self.am_word  = am_word\n",
    "        self.examples:list[str] = examples\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = f\"{self.am_word}: {self.examples}\"\n",
    "        return res\n",
    "\n",
    "    \n",
    "\n",
    "class SubDefinition(object):\n",
    "    def __init__(self, sub_type='', am_words=[]):\n",
    "        self.sub_type = sub_type\n",
    "        self.am_words = am_words\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = f\"(sub_type: {self.sub_type}):\\n\"\n",
    "        for am in self.am_words:\n",
    "            res += '\\t'\n",
    "            res += am.__str__()\n",
    "            res += ',\\n'\n",
    "        return res + ']'\n",
    "    \n",
    "\n",
    "class Definition(object):\n",
    "    \n",
    "    def __init__(self, definition='', sub_definitions=[]):\n",
    "        self.definition      = definition \n",
    "        self.sub_definitions = sub_definitions\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        res = f\"{self.definition}\\n\"\n",
    "        for sub in self.sub_definitions:\n",
    "            res += sub.__str__() + '\\n'\n",
    "        return res\n",
    "        \n",
    "        \n",
    "\n",
    "class DefinitionByType(object):\n",
    "    def __init__(self, word_type, definitions):\n",
    "        self.word_type = word_type\n",
    "        self.definitions = definitions\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        res = f\"(type: {self.word_type}):\\n\"\n",
    "        for defi in self.definitions:\n",
    "            res += defi.__str__()\n",
    "        return res\n",
    "    \n",
    "        \n",
    "class EnWord(object):\n",
    "    def __init__(self, en_word, definitions_by_type):\n",
    "        self.en_word = en_word\n",
    "        self.definitions_by_type = definitions_by_type\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = f\"--{self.en_word}--\\n\"\n",
    "        for defi in self.definitions_by_type:\n",
    "            res += defi.__str__()\n",
    "        return res + '\\n'\n",
    "        \n",
    "\n",
    "\"\"\"=============================================================================================\"\"\"\n",
    "        \n",
    "        \n",
    "def get_examples(content):\n",
    "    for i in range(len(content)):\n",
    "        if not content[i].startswith('<x>'):\n",
    "            raise Exception(f\"not an example: {content[i]}\")\n",
    "        \n",
    "        content[i] = content[i][3:].strip()\n",
    "    return content\n",
    "    \n",
    "    \n",
    "def get_am_words(content):\n",
    "    i_indexes = []\n",
    "    for i, line in enumerate(content):\n",
    "        if line.startswith('<i>'):\n",
    "            i_indexes.append(i)\n",
    "    \n",
    "    if len(i_indexes) == 0:\n",
    "        return [AmWord('', get_examples(content))]\n",
    "    \n",
    "    am_words = []\n",
    "    \n",
    "    if i_indexes[0] != 0:\n",
    "        am_words.append(AmWord('', get_examples(content[:i_indexes[0]])))\n",
    "    \n",
    "    con = None\n",
    "    for i in range(len(i_indexes)):\n",
    "        if i == len(i_indexes) - 1:\n",
    "            con = content[i_indexes[i]+1:]\n",
    "        else:\n",
    "            con = content[i_indexes[i]+1:i_indexes[i+1]]\n",
    "        am_words.append(AmWord(content[i_indexes[i]][3:].strip(), get_examples(con)))\n",
    "        \n",
    "    return am_words\n",
    "        \n",
    "def get_sub_definitions(content):\n",
    "    s_indexes = []\n",
    "    for i, line in enumerate(content):\n",
    "        if line.startswith('<s>'):\n",
    "            s_indexes.append(i)\n",
    "    \n",
    "    if len(s_indexes) == 0:\n",
    "        return [SubDefinition('', get_am_words(content))]\n",
    "    \n",
    "    sub_definitions = []\n",
    "    \n",
    "    if s_indexes[0] != 0:\n",
    "        sub_definitions.append(SubDefinition('', get_am_words(content[:s_indexes[0]])))\n",
    "    \n",
    "    con = None\n",
    "    for i in range(len(s_indexes)):\n",
    "        if i == len(s_indexes) - 1:\n",
    "            con = content[s_indexes[i]+1:]\n",
    "        else:\n",
    "            con = content[s_indexes[i]+1:s_indexes[i+1]]\n",
    "        sub_definitions.append(SubDefinition(content[s_indexes[i]][3:].strip(), get_am_words(con)))\n",
    "        \n",
    "    return sub_definitions\n",
    "        \n",
    "\n",
    "def get_definitions(content):\n",
    "    b_indexes = []\n",
    "    for i, line in enumerate(content):\n",
    "        if line.startswith('<b>'):\n",
    "            b_indexes.append(i)\n",
    "    \n",
    "    if len(b_indexes) == 0:\n",
    "        return [Definition('', get_sub_definitions(content))]\n",
    "    \n",
    "    definitions = []\n",
    "    \n",
    "    if b_indexes[0] != 0:\n",
    "        definitions.append(Definition('', get_sub_definitions(content[:b_indexes[0]])))\n",
    "    \n",
    "    con = None\n",
    "    for i in range(len(b_indexes)):\n",
    "        if i == len(b_indexes) - 1:\n",
    "            con = content[b_indexes[i]+1:]\n",
    "        else:\n",
    "            con = content[b_indexes[i]+1:b_indexes[i+1]]\n",
    "        definitions.append(Definition(content[b_indexes[i]][3:].strip(), get_sub_definitions(con)))\n",
    "    \n",
    "    return definitions\n",
    "        \n",
    "def get_definitions_by_type(content):\n",
    "    t_indexes = []\n",
    "    for i, line in enumerate(content):\n",
    "        if line.startswith('<t>'):\n",
    "            t_indexes.append(i)\n",
    "            \n",
    "    if len(t_indexes) == 0:\n",
    "        return [DefinitionByType('', get_definitions(content))]\n",
    "    \n",
    "    definitions_by_type = []\n",
    "\n",
    "    if t_indexes[0] != 0:\n",
    "        definitions_by_type.append(DefinitionByType('', get_definitions(content[:t_indexes[0]])))\n",
    "      \n",
    "    con = None\n",
    "    for i in range(len(t_indexes)):\n",
    "        if i == len(t_indexes) - 1:\n",
    "            con = content[t_indexes[i]+1:]\n",
    "        else:\n",
    "            con = content[t_indexes[i]+1: t_indexes[i+1]]\n",
    "            \n",
    "        definitions_by_type.append(DefinitionByType(content[t_indexes[i]][3:].strip(), get_definitions(con)))\n",
    "        \n",
    "    return definitions_by_type\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "def get_word(content):\n",
    "    if not content[0].startswith('<w>'):\n",
    "        raise Exception(f\"couldn't find the english word {content[0]}\")\n",
    "        \n",
    "    en_word = content[0][3:].strip()\n",
    "    definitions_by_type = get_definitions_by_type(content[1:])\n",
    "    \n",
    "    return EnWord(en_word, definitions_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fc3d245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "content = \"\"\"<w>a\n",
    "<t>(art.)\n",
    "<s>mas.\n",
    "<i>yan\n",
    "<x>ẓeṛiɣ yan urgaz\n",
    "<s>fem.\n",
    "<i>yat\n",
    "<x>yat tefruxt ad nn-unniɣ\"\"\"\n",
    "content2 = \"\"\"<w>zucchini squach\n",
    "<t>(n.)\n",
    "<i>taxsayt izbubn, tixsayin izbuben\n",
    "<x>ur ar ictta taxsayt izbubn\n",
    "<i>taḥṛcit, tiḥṛciyin\n",
    "<x>ur ar ictta taḥṛcit\"\"\"\n",
    "content = content2.split('\\n')\n",
    "word = get_word(content)\n",
    "# print(word)\n",
    "con = sqlite3.connect(\"db.sqlite3\")\n",
    "cursor = con.cursor()\n",
    "save_word(word, cursor)\n",
    "con.commit()\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5f5a026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids = {'': 1, '(aux. v.)': 2, '(comp.)': 3, '(pron. & conj.)': 4, '(art.)': 5, '(pref.)': 6, '(adj. & adv. & pron.)': 7, '(interj.)': 8, '(conj. & adj. & pron.)': 9, '(prefix.)': 10, '(exp.)': 11, '(perp.)': 12, '(prep. & conj.)': 13, '(adj. & pron. & conj.)': 14, '(pl. n.)': 15, '(adj. & pron.)': 16, '(adv & conj.)': 17, '(adv. & pron.)': 18, '(n. & adj. & adv.)': 19, '(expr.)': 20, '(conj. & pron.)': 21, '(det.)': 22, '(adv. & n.)': 23, '(conj.)': 24, '(n. pl.)': 25, '(n.)': 26, '(v.)': 27, '(adj & n.)': 28, '(adv.)': 29, '(adj. & conj.)': 30, '(adj. & adv.)': 31, '(super.)': 32, '(pre. & adv.)': 33, '(adv & prep.)': 34, '(pron.)': 35, '(adj. & n.)': 36, '(adj. & prep.)': 37, '(adv. & prep.)': 38, '(prep. & conj. & adv.)': 39, '(adj.)': 40, '(prep.)': 41, '(f&m. use.)': 42, '(inter.)': 43, '(adv. & prep. & adj.)': 44, '(abbrev.)': 45}\n",
    "s_ids = {'': 1, 'mas. fem.': 2, 'fem.': 3, 'super- (pref.).': 4, 'fem. sg.': 5, 'for instects.': 6, 'mas. pl.': 7, 'mas. sg.': 8, 'mas.': 9, 'fem. pl.': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c3cbe90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont forget last word\n",
    "\n",
    "def save_word(word, cursor):\n",
    "    \n",
    "    # save en_word\n",
    "    cursor.execute('insert into en_words(en_word) values(?)', (word.en_word,))\n",
    "    id_en_word = cursor.lastrowid\n",
    "\n",
    "    \n",
    "    for def_by_type in word.definitions_by_type:\n",
    "        word_type = def_by_type.word_type\n",
    "        id_word_type = t_ids[word_type]\n",
    "        \n",
    "        for defi in def_by_type.definitions:\n",
    "            meaning = defi.definition\n",
    "            # insert definition\n",
    "            cursor.execute(\"insert into definitions(definition, id_en_word, id_word_type) values(?, ?, ?)\", (meaning, id_en_word, id_word_type))\n",
    "            id_definition = cursor.lastrowid\n",
    "            \n",
    "            for sub_defi in defi.sub_definitions:\n",
    "                id_sub_type = s_ids[sub_defi.sub_type]\n",
    "                \n",
    "                for am_word_obj in sub_defi.am_words:\n",
    "                    am_word = am_word_obj.am_word\n",
    "                    # insert am_word_obj\n",
    "                    cursor.execute(\"insert into am_words(am_word, id_en_word, id_definition, id_sub_type) values(?, ?, ?, ?)\", (am_word, id_en_word, id_definition, id_sub_type))\n",
    "                    id_am_word = cursor.lastrowid\n",
    "                    \n",
    "                    for example in am_word_obj.examples:\n",
    "                        # insert examples\n",
    "                        cursor.execute(\"insert into examples(example, id_am_word) values(?, ?)\", (example, id_am_word))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8d40fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads the 130.000 lines of the file final_content.txt and gets all the words and stores them in the db\n",
    "def main():\n",
    "    con = sqlite3.connect(\"test.sqlite3\")\n",
    "    cursor = con.cursor()\n",
    "\n",
    "    with open(\"final_content.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            if not line:\n",
    "                break\n",
    "\n",
    "            if line.startswith('<w>'):\n",
    "                if content != []:\n",
    "                    save_word(get_word(content), cursor)\n",
    "                content = []\n",
    "\n",
    "            content.append(line)\n",
    "        \n",
    "        # last word\n",
    "        save_word(get_word(content), cursor)\n",
    "    con.commit()\n",
    "    con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
